{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Vehicle Coupon Recommendation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(x):\n",
    "    if x == \"Less than $12500\":\n",
    "        return \"12499\"\n",
    "    elif x == \"$12500 - $24999\":\n",
    "        return \"12500\"\n",
    "    elif x == \"$25000 - $37499\":\n",
    "        return \"25000\"\n",
    "    elif x == \"$37500 - $49999\":\n",
    "        return \"37500\"\n",
    "    elif x == \"$50000 - $62499\":\n",
    "        return \"50000\"\n",
    "    elif x == \"$62500 - $74999\":\n",
    "        return \"62500\"\n",
    "    elif x == \"$75000 - $87499\":\n",
    "        return \"75000\"\n",
    "    elif x == \"$87500 - $99999\":\n",
    "        return \"87500\"\n",
    "    elif x ==\"$100000 or More\":\n",
    "        return \"more than 100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rich(x):\n",
    "    if x in [\"62500\",\"75000\",\"87500\",\"more than 100k\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def middle(x):\n",
    "    if x in [\"25000\",\"37500\",\"50000\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def poor(x):\n",
    "    if x in [\"12499\",\"12500\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income\"]= df[\"income\"].apply(clear)\n",
    "df[\"rich\"] = df[\"income\"].apply(rich)\n",
    "df[\"middleclass\"] = df[\"income\"].apply(middle)\n",
    "df[\"poor\"] = df[\"income\"].apply(poor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age0\"] = df[\"age\"].apply(lambda x: 1 if x ==\"below21\" else 0)\n",
    "df[\"age21\"] = df[\"age\"].apply(lambda x: 1 if x in [\"21\",\"26\"] else 0)\n",
    "df[\"age31\"] = df[\"age\"].apply(lambda x: 1 if x in [\"31\",\"36\"] else 0)\n",
    "df[\"age41\"] = df[\"age\"].apply(lambda x: 1 if x in [\"41\",\"46\"] else 0)\n",
    "df[\"age51\"] = df[\"age\"].apply(lambda x: 1 if x in [\"50plus\"] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"age\"]\n",
    "del df[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['destination', 'passanger', 'weather', 'temperature', 'time', 'coupon',\n",
       "       'expiration', 'gender', 'maritalStatus', 'has_children', 'education',\n",
       "       'occupation', 'car', 'Bar', 'CoffeeHouse', 'CarryAway',\n",
       "       'RestaurantLessThan20', 'Restaurant20To50', 'toCoupon_GEQ5min',\n",
       "       'toCoupon_GEQ15min', 'toCoupon_GEQ25min', 'direction_same',\n",
       "       'direction_opp', 'Y', 'rich', 'middleclass', 'poor', 'age0', 'age21',\n",
       "       'age31', 'age41', 'age51'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['direction_opp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['car'], inplace=True)\n",
    "na_columns = ['Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50']\n",
    "df.drop(columns=['toCoupon_GEQ5min'], inplace=True)\n",
    "frequency_map = {\n",
    "    'never': 0,\n",
    "    'less1': 1,\n",
    "    '1~3': 2,\n",
    "    '4~8': 3,\n",
    "    'gt8': 4}\n",
    "\n",
    "frequency_cols = ['Restaurant20To50', 'RestaurantLessThan20', \n",
    "                      'CarryAway', 'CoffeeHouse', 'Bar']\n",
    "for col in frequency_cols:\n",
    "    df[col] = df[col].map(frequency_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['destination', 'passanger', 'weather', 'temperature', 'time', 'coupon',\n",
       "       'expiration', 'gender', 'maritalStatus', 'has_children', 'education',\n",
       "       'occupation', 'Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20',\n",
       "       'Restaurant20To50', 'toCoupon_GEQ15min', 'toCoupon_GEQ25min',\n",
       "       'direction_same', 'direction_opp', 'Y', 'rich', 'middleclass', 'poor',\n",
       "       'age0', 'age21', 'age31', 'age41', 'age51'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance'] = None\n",
    "df.loc[df['toCoupon_GEQ15min'] == 0, 'distance'] = 0\n",
    "df.loc[(df['toCoupon_GEQ15min'] == 1) & \\\n",
    "                (df['toCoupon_GEQ25min'] == 0), 'distance'] = 1\n",
    "df.loc[df['toCoupon_GEQ25min'] == 1, 'distance'] = 2\n",
    "df.distance = df.distance.astype('int64')\n",
    "df.drop(columns=['toCoupon_GEQ15min', 'toCoupon_GEQ25min'], inplace=True)\n",
    "df.has_children = df.has_children.astype(str)\n",
    "df.direction_same = df.direction_same.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Bar\"] = df[\"Bar\"].astype('int64')\n",
    "df[\"CoffeeHouse\"] = df[\"CoffeeHouse\"].astype('int64')\n",
    "df[\"CarryAway\"] = df[\"CarryAway\"].astype('int64')\n",
    "df[\"RestaurantLessThan20\"] = df[\"RestaurantLessThan20\"].astype('int64')\n",
    "df[\"Restaurant20To50\"] = df[\"Restaurant20To50\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"direction_same\"] = df[\"direction_same\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12079 entries, 22 to 12683\n",
      "Data columns (total 28 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   destination           12079 non-null  object\n",
      " 1   passanger             12079 non-null  object\n",
      " 2   weather               12079 non-null  object\n",
      " 3   temperature           12079 non-null  int64 \n",
      " 4   time                  12079 non-null  object\n",
      " 5   coupon                12079 non-null  object\n",
      " 6   expiration            12079 non-null  object\n",
      " 7   gender                12079 non-null  object\n",
      " 8   maritalStatus         12079 non-null  object\n",
      " 9   has_children          12079 non-null  object\n",
      " 10  education             12079 non-null  object\n",
      " 11  occupation            12079 non-null  object\n",
      " 12  Bar                   12079 non-null  int64 \n",
      " 13  CoffeeHouse           12079 non-null  int64 \n",
      " 14  CarryAway             12079 non-null  int64 \n",
      " 15  RestaurantLessThan20  12079 non-null  int64 \n",
      " 16  Restaurant20To50      12079 non-null  int64 \n",
      " 17  direction_same        12079 non-null  int64 \n",
      " 18  Y                     12079 non-null  int64 \n",
      " 19  rich                  12079 non-null  int64 \n",
      " 20  middleclass           12079 non-null  int64 \n",
      " 21  poor                  12079 non-null  int64 \n",
      " 22  age0                  12079 non-null  int64 \n",
      " 23  age21                 12079 non-null  int64 \n",
      " 24  age31                 12079 non-null  int64 \n",
      " 25  age41                 12079 non-null  int64 \n",
      " 26  age51                 12079 non-null  int64 \n",
      " 27  distance              12079 non-null  int64 \n",
      "dtypes: int64(17), object(11)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.has_children = df.has_children.astype(str)\n",
    "df.direction_same = df.direction_same.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df = pd.read_csv('/kaggle/working/clean_df.csv', \n",
    "#                        dtype={'has_children': str,\n",
    "#                              'direction_same': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import base\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2021\n",
    "\n",
    "x = df.drop(columns=['Y'])\n",
    "y = df.Y\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=RANDOM_SEED, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['destination', 'passanger', 'weather', 'temperature', 'time', 'coupon',\n",
       "       'expiration', 'gender', 'maritalStatus', 'has_children', 'education',\n",
       "       'occupation', 'Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20',\n",
       "       'Restaurant20To50', 'direction_same', 'rich', 'middleclass', 'poor',\n",
       "       'age0', 'age21', 'age31', 'age41', 'age51', 'distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_a = X_train.copy()\n",
    "X_test_a = X_test.copy()\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_predictors = ['destination', 'passanger', 'weather', 'time', 'coupon',\n",
    "            'expiration', 'maritalStatus', 'education',\n",
    "            'occupation', 'direction_same']\n",
    "for col in strong_predictors:\n",
    "    # create frequency encoder\n",
    "    freq_encoder = X_train_a.groupby(col).size() / len(X_train_a)\n",
    "    # fit_transform for X_train\n",
    "    X_train_a[col + '_freq'] = X_train_a[col].apply(lambda x: freq_encoder[x])\n",
    "    # transform for X_test\n",
    "    X_test_a[col + '_freq'] = X_test_a[col].apply(lambda x: freq_encoder[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldTargetEncoderTrain(base.BaseEstimator, base.TransformerMixin):\n",
    "    \"\"\"\n",
    "    This object contains a target encoder for a training set which should have\n",
    "    both X and y. \n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    feature:          string. Name of the feature in the training set.\n",
    "    target:           string. Name of the target in the training set.\n",
    "    n_fold:           default 5. Number of folds to use in KFold.\n",
    "    verbose:          bool, default True. If set to True, the correlation between the \n",
    "                      feature and the target will be calculated and printed out.\n",
    "    discard_original: bool,, default False. If set to True, the feature column will be \n",
    "                      deleted from the training set.\n",
    "                      \n",
    "    Example\n",
    "    ---------\n",
    "    train_target_encoder = KFoldTargetEncoderTrain(feature='A', target='target')\n",
    "    new_train = train_target_encoder.fit_transform(train)\n",
    "    \"\"\"\n",
    "    def __init__(self, feature, target, n_fold=5, verbose=True, discard_original=False):\n",
    "\n",
    "        self.feature = feature\n",
    "        self.target = target\n",
    "        self.n_fold = n_fold\n",
    "        self.verbose = verbose\n",
    "        self.discard_original = discard_original\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        \"\"\"\n",
    "        Transform the original training set. Notice this function can only encode \n",
    "        one feature once.\n",
    "        \n",
    "        Arguments:\n",
    "        ----------\n",
    "        X: A pandas DataFrame which should include both the feature and the target.\n",
    "        \n",
    "        Output:\n",
    "        X: A pandas DataFrame with the target encoding.\n",
    "        \"\"\"\n",
    "        \n",
    "        # notice this function can only encode one feature at a time\n",
    "        assert(type(self.feature) == str)\n",
    "        assert(type(self.target) == str)\n",
    "        assert(self.feature in X.columns)\n",
    "        assert(self.target in X.columns)\n",
    "\n",
    "        mean_of_target = X[self.target].mean()\n",
    "        kf = KFold(n_splits = self.n_fold, shuffle = True, random_state=RANDOM_SEED)\n",
    "        # create the target encoding\n",
    "        col_mean_name = self.feature + '_target'\n",
    "        X[col_mean_name] = np.nan\n",
    "\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            X.loc[X.index[val_index], col_mean_name] = \\\n",
    "            X_val[self.feature].map(X_train.groupby(self.feature)[self.target].mean())\n",
    "        # missing value imputation\n",
    "        X[col_mean_name].fillna(mean_of_target, inplace = True)\n",
    "\n",
    "        if self.verbose:\n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between {} and, {} is {}.'.\\\n",
    "                  format(col_mean_name, self.target,\n",
    "                         np.corrcoef(X[self.target].values, encoded_feature)[0][1]))\n",
    "        # discard orginal feature column if needed\n",
    "        if self.discard_original:\n",
    "            X = X.drop(self.target, axis=1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n",
    "    \"\"\"\n",
    "    This object contains a target encoder for a testing set which should have\n",
    "    both X and y.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    train:          pandas DataFrame. The training DataFrame with the feature and \n",
    "                    the target encoded column of it.\n",
    "    feature:        string. The column name of the feature.\n",
    "    feature_target: string. The column name of the feature_target that \n",
    "                    has been calculated in the training set.\n",
    "                    \n",
    "    Example\n",
    "    ---------\n",
    "    test_target_encoder = KFoldTargetEncoderTest(new_train, 'A', 'A_target')\n",
    "    new_test = test_target_encoder.transform(test)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, train, feature, feature_target):\n",
    "        \n",
    "        self.train = train\n",
    "        self.feature = feature\n",
    "        self.feature_target = feature_target\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        \"\"\"\n",
    "        Transform the testing set based on K-fold target encoder of the training set.\n",
    "        Notice this function can only encode one feature at a time.\n",
    "        \n",
    "        Argument\n",
    "        --------\n",
    "        X: pandas DataFrame. The testing set to be transformed.\n",
    "        \n",
    "        Output\n",
    "        --------\n",
    "        X: A pandas DataFrame with transformed target encoding.\n",
    "        \"\"\"\n",
    "\n",
    "        mean = self.train[[self.feature,self.feature_target]].groupby(self.feature).mean().reset_index() \n",
    "        \n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.feature]] = row[self.feature_target]\n",
    "\n",
    "        \n",
    "        X[self.feature_target] = X[self.feature]\n",
    "        X = X.replace({self.feature_target: dd})\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between destination_target and, Y is 0.12332191934825186.\n",
      "Correlation between passanger_target and, Y is 0.13335529496845147.\n",
      "Correlation between weather_target and, Y is 0.09363674414140329.\n",
      "Correlation between time_target and, Y is 0.10659903687517253.\n",
      "Correlation between coupon_target and, Y is 0.2607623636443679.\n",
      "Correlation between expiration_target and, Y is 0.1289398045537721.\n",
      "Correlation between maritalStatus_target and, Y is 0.058415339358508636.\n",
      "Correlation between education_target and, Y is 0.048141650469191236.\n",
      "Correlation between occupation_target and, Y is 0.08877145087009404.\n",
      "Correlation between direction_same_target and, Y is 0.00224754432161267.\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([X_train_a, y_train], axis=1)\n",
    "new_train = train_df.copy()\n",
    "for feature in strong_predictors:\n",
    "    train_target_encoder = KFoldTargetEncoderTrain(feature, 'Y')\n",
    "    new_train = train_target_encoder.fit_transform(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test_a, y_test], axis=1)\n",
    "new_test = test_df.copy()\n",
    "strong_predictors_targets = []\n",
    "for feature in strong_predictors:\n",
    "    strong_predictors_targets.append(feature + '_target')\n",
    "for feature, feature_target in zip(strong_predictors, strong_predictors_targets):\n",
    "    test_target_encoder = KFoldTargetEncoderTest(new_train, feature, feature_target)\n",
    "    new_test = test_target_encoder.transform(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.drop(columns=strong_predictors, inplace=True)\n",
    "new_test.drop(columns=strong_predictors, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a = new_train.drop(columns=['Y'])\n",
    "X_test_a = new_test.drop(columns=['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9663 entries, 10640 to 9790\n",
      "Data columns (total 37 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   temperature            9663 non-null   int64  \n",
      " 1   gender                 9663 non-null   object \n",
      " 2   has_children           9663 non-null   object \n",
      " 3   Bar                    9663 non-null   int64  \n",
      " 4   CoffeeHouse            9663 non-null   int64  \n",
      " 5   CarryAway              9663 non-null   int64  \n",
      " 6   RestaurantLessThan20   9663 non-null   int64  \n",
      " 7   Restaurant20To50       9663 non-null   int64  \n",
      " 8   rich                   9663 non-null   int64  \n",
      " 9   middleclass            9663 non-null   int64  \n",
      " 10  poor                   9663 non-null   int64  \n",
      " 11  age0                   9663 non-null   int64  \n",
      " 12  age21                  9663 non-null   int64  \n",
      " 13  age31                  9663 non-null   int64  \n",
      " 14  age41                  9663 non-null   int64  \n",
      " 15  age51                  9663 non-null   int64  \n",
      " 16  distance               9663 non-null   int64  \n",
      " 17  destination_freq       9663 non-null   float64\n",
      " 18  passanger_freq         9663 non-null   float64\n",
      " 19  weather_freq           9663 non-null   float64\n",
      " 20  time_freq              9663 non-null   float64\n",
      " 21  coupon_freq            9663 non-null   float64\n",
      " 22  expiration_freq        9663 non-null   float64\n",
      " 23  maritalStatus_freq     9663 non-null   float64\n",
      " 24  education_freq         9663 non-null   float64\n",
      " 25  occupation_freq        9663 non-null   float64\n",
      " 26  direction_same_freq    9663 non-null   float64\n",
      " 27  destination_target     9663 non-null   float64\n",
      " 28  passanger_target       9663 non-null   float64\n",
      " 29  weather_target         9663 non-null   float64\n",
      " 30  time_target            9663 non-null   float64\n",
      " 31  coupon_target          9663 non-null   float64\n",
      " 32  expiration_target      9663 non-null   float64\n",
      " 33  maritalStatus_target   9663 non-null   float64\n",
      " 34  education_target       9663 non-null   float64\n",
      " 35  occupation_target      9663 non-null   float64\n",
      " 36  direction_same_target  9663 non-null   float64\n",
      "dtypes: float64(20), int64(15), object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train_a.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_a = X_train_a.select_dtypes(['int64', 'float64']).columns\n",
    "cat_features_a = X_train_a.select_dtypes(['object']).columns\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_transformer = OneHotEncoder()\n",
    "preprocessor_a = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_features_a),\n",
    "    ('cat', cat_transformer, cat_features_a)\n",
    "])\n",
    "X_train_a = preprocessor_a.fit_transform(X_train_a)\n",
    "X_test_a = preprocessor_a.transform(X_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9663, 39), (2416, 39))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_a.shape, X_test_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9663, 27)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_clf = LogisticRegression(solver='saga', max_iter=500,\n",
    "                               random_state=RANDOM_SEED)\n",
    "dt_clf = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "bnb_clf = BernoulliNB()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "lsvm_clf = LinearSVC(max_iter=5000, dual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_params = dict(C=loguniform(1e-1, 1e2),\n",
    "                     penalty=['l1', 'l2'])\n",
    "dt_params = dict(criterion=['gini', 'entropy'],\n",
    "                 min_samples_split=[2, 4, 6, 8, 10],\n",
    "                 max_depth=[2, 4, 6, 8, 10])\n",
    "bnb_params = dict(alpha=loguniform(1e-1, 1e0))\n",
    "knn_params = dict(n_neighbors=[2, 4, 6, 8, 10, 12, 14, 20],\n",
    "               weights=['uniform', 'distance'],\n",
    "               metric=['euclidean', 'manhattan'])\n",
    "lsvm_params = dict(C=loguniform(1e-1, 1e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = [logreg_clf, dt_clf, bnb_clf, knn_clf, lsvm_clf]\n",
    "params_list = [logreg_params, dt_params, bnb_params, knn_params, lsvm_params]\n",
    "model_names = ['Logistic Regression', 'Decison Tree', 'Bernoulli Naive Bayes',\n",
    "               'KNN Classifier', 'Linear SVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7892/3777217377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model_suffix, clf_list=clf_list, params_list=params_list):\n",
    "    for i in range(len(clf_list)):\n",
    "        # model training with RandomizedSearchCV\n",
    "        rscv = RandomizedSearchCV(estimator=clf_list[i],\n",
    "                                  param_distributions=params_list[i],\n",
    "                                  n_jobs=-1, random_state=RANDOM_SEED).fit(X, y)\n",
    "        # store cv results\n",
    "        globals()['rscv%s' % model_suffix[i]] = pd.DataFrame(rscv.cv_results_)\n",
    "        # store the best model\n",
    "        globals()['best%s' % model_suffix[i]] = rscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_best_result(model_list, model_suffix):\n",
    "    # store the best results into a dataframe\n",
    "    for i in range(len(model_list)):\n",
    "        globals()['df%s' % model_suffix[i]] = model_list[i].query('rank_test_score == 1')\\\n",
    "        [['params', 'mean_test_score', 'std_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(clf_list, model_names, X_test, y_test):\n",
    "    test_acc = []\n",
    "    f1_score = []\n",
    "    for clf in clf_list:\n",
    "        test_acc.append(clf.score(X_test, y_test))\n",
    "        f1_score.append(metrics.f1_score(y_test, clf.predict(X_test)))\n",
    "    return pd.DataFrame(data={'model': model_names, 'test_acc': test_acc, 'f1_score': f1_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfredo\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Alfredo\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Alfredo\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\Alfredo\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 572, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\Alfredo\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 956, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\Alfredo\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 738, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\Alfredo\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'Work'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Alfredo\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Work'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7892/4284761766.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_suffix_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'_logreg_a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_dt_a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_bnb_a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_knn_a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_lsvm_a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_suffix_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# record best results in cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7892/1127551944.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X, y, model_suffix, clf_list, params_list)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m# model training with RandomizedSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         rscv = RandomizedSearchCV(estimator=clf_list[i],\n\u001b[0m\u001b[0;32m      5\u001b[0m                                   \u001b[0mparam_distributions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                   n_jobs=-1, random_state=RANDOM_SEED).fit(X, y)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1508\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Work'"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "model_suffix_a = ['_logreg_a', '_dt_a', '_bnb_a', '_knn_a', '_lsvm_a']\n",
    "train_model(X_train, y_train, model_suffix_a)\n",
    "\n",
    "# record best results in cross validation\n",
    "rscv_list_a = [rscv_logreg_a, rscv_dt_a, rscv_bnb_a, rscv_knn_a, rscv_lsvm_a]\n",
    "record_best_result(rscv_list_a, model_suffix_a)\n",
    "\n",
    "# output the best results as a dataframe\n",
    "df_list_a = [df_logreg_a, df_dt_a, df_bnb_a, df_knn_a, df_lsvm_a]\n",
    "for df, model in zip(df_list_a, model_names):\n",
    "    df['model'] = model\n",
    "result_df_a = pd.concat(df_list_a)\n",
    "\n",
    "# check test scores\n",
    "best_clfs_a = [best_logreg_a, best_dt_a, best_bnb_a, best_knn_a, best_lsvm_a]\n",
    "test_result_a = model_eval(best_clfs_a, model_names, X_test_a, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.8670003076119907, 'penalty': 'l2'}</td>\n",
       "      <td>0.681464</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 6, 'crit...</td>\n",
       "      <td>0.689849</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>Decison Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'min_samples_split': 8, 'max_depth': 6, 'crit...</td>\n",
       "      <td>0.689849</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>Decison Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'alpha': 0.40362520519080136}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'alpha': 0.5412144223247399}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'alpha': 0.13770419055707592}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'alpha': 0.20543436020515712}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'alpha': 0.9936725240317664}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'alpha': 0.13432670922874754}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'alpha': 0.1510056183136176}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'alpha': 0.5661420703684213}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'alpha': 0.4593677628057311}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'alpha': 0.6085694290112444}</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 12, 'me...</td>\n",
       "      <td>0.704647</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>KNN Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 0.24237461166526628}</td>\n",
       "      <td>0.681361</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>Linear SVM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "2         {'C': 0.8670003076119907, 'penalty': 'l2'}         0.681464   \n",
       "3  {'min_samples_split': 2, 'max_depth': 6, 'crit...         0.689849   \n",
       "8  {'min_samples_split': 8, 'max_depth': 6, 'crit...         0.689849   \n",
       "0                     {'alpha': 0.40362520519080136}         0.647623   \n",
       "1                      {'alpha': 0.5412144223247399}         0.647623   \n",
       "2                     {'alpha': 0.13770419055707592}         0.647623   \n",
       "3                     {'alpha': 0.20543436020515712}         0.647623   \n",
       "4                      {'alpha': 0.9936725240317664}         0.647623   \n",
       "5                     {'alpha': 0.13432670922874754}         0.647623   \n",
       "6                      {'alpha': 0.1510056183136176}         0.647623   \n",
       "7                      {'alpha': 0.5661420703684213}         0.647623   \n",
       "8                      {'alpha': 0.4593677628057311}         0.647623   \n",
       "9                      {'alpha': 0.6085694290112444}         0.647623   \n",
       "6  {'weights': 'distance', 'n_neighbors': 12, 'me...         0.704647   \n",
       "5                         {'C': 0.24237461166526628}         0.681361   \n",
       "\n",
       "   std_test_score                  model  \n",
       "2        0.007133    Logistic Regression  \n",
       "3        0.002976           Decison Tree  \n",
       "8        0.002976           Decison Tree  \n",
       "0        0.012898  Bernoulli Naive Bayes  \n",
       "1        0.012898  Bernoulli Naive Bayes  \n",
       "2        0.012898  Bernoulli Naive Bayes  \n",
       "3        0.012898  Bernoulli Naive Bayes  \n",
       "4        0.012898  Bernoulli Naive Bayes  \n",
       "5        0.012898  Bernoulli Naive Bayes  \n",
       "6        0.012898  Bernoulli Naive Bayes  \n",
       "7        0.012898  Bernoulli Naive Bayes  \n",
       "8        0.012898  Bernoulli Naive Bayes  \n",
       "9        0.012898  Bernoulli Naive Bayes  \n",
       "6        0.008309         KNN Classifier  \n",
       "5        0.007813             Linear SVM  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.687914</td>\n",
       "      <td>0.741781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decison Tree</td>\n",
       "      <td>0.698262</td>\n",
       "      <td>0.751449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>0.658526</td>\n",
       "      <td>0.710018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.711093</td>\n",
       "      <td>0.760959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.687086</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  test_acc  f1_score\n",
       "0    Logistic Regression  0.687914  0.741781\n",
       "1           Decison Tree  0.698262  0.751449\n",
       "2  Bernoulli Naive Bayes  0.658526  0.710018\n",
       "3         KNN Classifier  0.711093  0.760959\n",
       "4             Linear SVM  0.687086  0.740741"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_a\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
